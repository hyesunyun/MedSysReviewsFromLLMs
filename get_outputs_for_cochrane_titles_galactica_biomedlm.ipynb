{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import galai as gal\n",
    "import torch\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "galactica_model = gal.load_model(\"standard\", num_gpus=1)\n",
    "\n",
    "biomedlm_tokenizer = GPT2Tokenizer.from_pretrained(\"stanford-crfm/BioMedLM\")\n",
    "biomedlm_model = GPT2LMHeadModel.from_pretrained(\"stanford-crfm/BioMedLM\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df = pd.read_csv(\"./cochrane_reviews_latest_by_topic_20230223.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_galactica_output_title(row):\n",
    "    title = row['title']\n",
    "    prompt = 'Title: ' + title + '\\n\\n'\n",
    "    # using max length of 2048 which is the max for galactica\n",
    "    # the parameteres for galactica generate method is from galactica's github (https://github.com/paperswithcode/galai)\n",
    "    return galactica_model.generate(prompt, new_doc=True, top_p=0.7, max_length=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_galactica_output_hashtag(row):\n",
    "    title = row['title']\n",
    "    prompt = '# ' + title + '\\n\\n'\n",
    "    # using max length of 2048 which is the max for galactica\n",
    "    # the parameteres for galactica generate method is from galactica's github (https://github.com/paperswithcode/galai)\n",
    "    return galactica_model.generate(prompt, new_doc=True, top_p=0.7, max_length=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_biomedlm_output(row):\n",
    "    title = row['title']\n",
    "    prompt = 'Title: ' + title\n",
    "    input_ids = biomedlm_tokenizer.encode(\n",
    "        prompt, return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    # using max length of 1024 which is the max for biomedlm\n",
    "    output = biomedlm_model.generate(input_ids, do_sample=True, max_length=1024, top_k=50)\n",
    "\n",
    "    return biomedlm_tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['galactica_output_title'] = df.progress_apply(get_galactica_output_title, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['galactica_output_hashtag'] = df.progress_apply(get_galactica_output_hashtag, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['biomedlm_output'] = df.progress_apply(get_biomedlm_output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./llm_outputs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
